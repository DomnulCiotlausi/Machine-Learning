{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\vladc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import textstat\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from pandas import DataFrame, read_csv\n",
    "from matplotlib import pyplot\n",
    "from nltk import ngrams\n",
    "from nltk.parse import stanford\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, SVR\n",
    "from scipy.sparse import hstack\n",
    "from textblob import TextBlob as blob_en\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "from textblob_de import TextBlobDE as blob_de\n",
    "from langdetect import detect\n",
    "\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "tagger = PerceptronTagger()\n",
    "\n",
    "\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    tweetId = []\n",
    "    tweetText = []\n",
    "    userId = []\n",
    "    imageId = []\n",
    "    username = []\n",
    "    timestamp = []\n",
    "    label = []\n",
    "    index = []\n",
    "    \n",
    "    path = os.path.join(r\"D:\\Python\\media eval\", file_name)\n",
    "    f = open(path, encoding=\"utf8\")\n",
    "    \n",
    "    ok = True\n",
    "    for line in f.readlines():\n",
    "        lines = line.strip('\\n').split(\"\\t\")\n",
    "        if ok:\n",
    "            ok = False\n",
    "            index = lines\n",
    "        else:\n",
    "            tweetId.append(lines[0])\n",
    "            tweetText.append(lines[1])\n",
    "            userId.append(lines[2])\n",
    "            imageId.append(lines[3])\n",
    "            username.append(lines[4])\n",
    "            timestamp.append(lines[5])\n",
    "            label.append(lines[6])\n",
    "    f.close()\n",
    "    \n",
    "    df = DataFrame({\n",
    "        index[0] : tweetId, \n",
    "        index[1]: tweetText, \n",
    "        index[2]: userId, \n",
    "        index[3]: imageId, \n",
    "        index[4]: username, \n",
    "        index[5]: timestamp, \n",
    "        index[6]: label})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_file(r\"mediaeval-2015-trainingset.txt\")\n",
    "test_df = read_file(r\"mediaeval-2015-testset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake' 'humor' 'real']\n",
      "['fake' 'real']\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "print(train_df[\"label\"].unique())\n",
    "train_df[\"label\"] = np.where(train_df[\"label\"] == \"humor\", \"fake\", train_df[\"label\"])\n",
    "print(train_df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(object): \n",
    "\n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-zÃ€-Ã¿0-9]+)|([^0-9A-Za-zÃ€-Ã¿ \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())  \n",
    "    \n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        try:\n",
    "            language = detect(tweet)\n",
    "            analysis = blob_en(self.clean_tweet(tweet))\n",
    "        except:\n",
    "            return [0.0,0.0]\n",
    "        \n",
    "        if language == 'fr':\n",
    "            analysis = blob_en(self.clean_tweet(tweet), pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "        elif language == 'de':\n",
    "            analysis = blob_de(self.clean_tweet(tweet))\n",
    "\n",
    "        return (analysis.sentiment[0], analysis.sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(df):\n",
    "    lang = []\n",
    "    for text in df[\"tweetText\"]:\n",
    "        try:\n",
    "            lang.append(detect(text))\n",
    "        except:\n",
    "            lang.append('en')\n",
    "    return lang\n",
    "\n",
    "def count_char(df1, df2, l, s):\n",
    "    for p in l:\n",
    "        p_list = []\n",
    "        for text in df2[\"tweetText\"]:\n",
    "            p_list.append(text.count(p))\n",
    "        df1[s + p] = p_list\n",
    "    return df1\n",
    "\n",
    "def normalize(df):\n",
    "    x = df.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = DataFrame(x_scaled, columns=[c for c in df])\n",
    "    return df\n",
    "\n",
    "def analyse(df1, df2): \n",
    "    analyser = Sentiment() \n",
    "    \n",
    "    sen_list = []\n",
    "    sub_list = []\n",
    "    for text in df2[\"tweetText\"]:\n",
    "        sentiment = analyser.get_tweet_sentiment(text)\n",
    "        sen_list.append(sentiment[0])\n",
    "        sub_list.append(sentiment[1])\n",
    "    df1[\"sentiment\"] = sen_list\n",
    "    df1[\"subjectivity\"] = sub_list\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def encode_label(l):\n",
    "    labels = []\n",
    "    for text in l:\n",
    "        if text == \"fake\":\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels\n",
    "\n",
    "def pos_tag(df1, df2):\n",
    "    pool = ThreadPool(4) \n",
    "#     results = pool.map(my_function, my_array)\n",
    "    \n",
    "    pos_pd = DataFrame()\n",
    "    for text in df2[\"tweetText\"]:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = nltk.pos_tag(tokens)\n",
    "        \n",
    "        tokens = [x[1] for x in tokens]\n",
    "        \n",
    "        dummies = pd.get_dummies(tokens, prefix = \"pos_tag\")\n",
    "        df1 = pd.concat([df1, dummies], axis=1)\n",
    "        \n",
    "    print (df1.shape)\n",
    "    return df1\n",
    "\n",
    "def helper(text):\n",
    "    tagset = None\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = nltk.tag._pos_tag(tokens, tagset, tagger)\n",
    "    tokens = [x[1] for x in tokens]\n",
    "    \n",
    "    return tokens\n",
    "    \n",
    "def work(df1, df2):\n",
    "    pool = ThreadPool(8) \n",
    "    results = pool.map(helper, df2[\"tweetText\"].values)\n",
    "\n",
    "    rez = []\n",
    "    for x in results:\n",
    "        str = \"\"\n",
    "        for tok in x:\n",
    "            str = str + tok + \" \"\n",
    "        rez.append(str)\n",
    "    pos_pd = pd.DataFrame(rez, columns=[\"Sin\"])\n",
    "    \n",
    "    word_vectorizer.fit(pos_pd[\"Sin\"])\n",
    "    n_grams = word_vectorizer.transform(pos_pd[\"Sin\"])\n",
    "    \n",
    "    temp = DataFrame(n_grams.toarray())\n",
    "    print (\"Shape before conncat: \", df1.shape)\n",
    "    df1 = pd.concat([df1, temp], axis = 1)\n",
    "    print (\"Shape after conncat: \", df1.shape)    \n",
    "        \n",
    "    return df1\n",
    "    \n",
    "# def pos_tag(df1, df2):\n",
    "#     pool = ThreadPool(4) \n",
    "#     results = pool.map(my_function, my_array)\n",
    "    \n",
    "#     pos_pd = DataFrame()\n",
    "#     for text in df2[\"tweetText\"]:\n",
    "#         tokens = nltk.word_tokenize(text)\n",
    "#         tokens = nltk.pos_tag(tokens)\n",
    "        \n",
    "#         tokens = [x[1] for x in tokens]\n",
    "        \n",
    "#         dummies = pd.get_dummies(tokens, prefix = \"pos_tag\")\n",
    "#         df1 = pd.concat([df1, dummies], axis=1)\n",
    "        \n",
    "#     print (df1.shape)\n",
    "#     return df1\n",
    "    \n",
    "def reading_score(df1, df2):\n",
    "    flesch = []\n",
    "    automated = []\n",
    "    dale = []\n",
    "    difficult = []\n",
    "    \n",
    "    for line in df2[\"tweetText\"]: \n",
    "        flesch.append(textstat.flesch_reading_ease(line))\n",
    "        automated.append(textstat.automated_readability_index(line))\n",
    "        dale.append(textstat.dale_chall_readability_score(line))\n",
    "        difficult.append(textstat.difficult_words(line))\n",
    "    \n",
    "    df1[\"flesch\"] = flesch\n",
    "    df1[\"automated\"] = automated\n",
    "    df1[\"dale\"]= dale\n",
    "    df1[\"difficult\"] = difficult\n",
    "    \n",
    "    return df1\n",
    "\n",
    "def basic_metrics(df1, df2):\n",
    "    df1[\"len\"] = [len(x) for x in df2[\"tweetText\"]]\n",
    "    df1[\"word_len\"] = [len(x.split()) for x in df2[\"tweetText\"]]\n",
    "    df1[\"upper\"] = [sum(1 for c in x if c.isupper()) for x in df2[\"tweetText\"]]\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = [\"ðŸ˜‚\",\"ðŸ˜³\",\"ðŸ˜±\",\"ðŸ˜­\",\"ðŸ˜¢\",\"âš¡\",\"â˜”\",\"ðŸŒ€\",\"ðŸ˜¨\",\"ðŸŒŠ\",\"â¤\",\"ðŸ—½\",\"ðŸƒ\",\"ðŸ‘Ž\"]\n",
    "languages = [\"lang_en\", \"lang_fr\", \"lang_de\", \"lang_es\"]\n",
    "\n",
    "def feature_selection(df):\n",
    "    feature_df = DataFrame()\n",
    "    \n",
    "    #ngrams\n",
    "    start = time.time()\n",
    "    word_vectorizer.fit(df[\"tweetText\"])\n",
    "    n_grams = word_vectorizer.transform(df[\"tweetText\"])\n",
    "    \n",
    "    temp = DataFrame(n_grams.toarray())\n",
    "    feature_df = pd.concat([feature_df, temp])\n",
    "    print (\"N-grams: \", time.time() - start)\n",
    "    \n",
    "#     start = time.time()\n",
    "#     feature_df = pos_tag(feature_df, df)\n",
    "#     print (\"Pos_tag:\" , time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    feature_df = work(feature_df, df)\n",
    "    print (\"Pos_tag:\" , time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    feature_df = analyse(feature_df, df)\n",
    "    feature_df = reading_score(feature_df, df)\n",
    "    print (\"Reading Score:\" , time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    feature_df = basic_metrics(feature_df, df)\n",
    "    print (\"Basic_Metrics:\" , time.time() - start)\n",
    "    \n",
    "    start = time.time()\n",
    "    feature_df[\"lang\"] = detect_lang(df) \n",
    "    dummies = pd.get_dummies(feature_df[\"lang\"], prefix = \"lang\")\n",
    "    feature_df = pd.concat([feature_df, dummies], axis=1)\n",
    "    feature_df = feature_df.drop([\"lang\"], axis=1)\n",
    "    print (\"Language:\" , time.time() - start)\n",
    "    \n",
    "    for c in feature_df:\n",
    "        try:\n",
    "            if not c in languages and \"lang_\" in c:\n",
    "                feature_df = feature_df.drop(c, axis=1)\n",
    "        except:\n",
    "            None\n",
    "    \n",
    "    start = time.time()\n",
    "    feature_df = count_char(feature_df, df, string.punctuation, \"char_\")\n",
    "    feature_df = count_char(feature_df, df, emojis, \"emoji_\")\n",
    "    print (\"Char+Emoji:\" , time.time() - start)\n",
    "    \n",
    "    feature_df[\"label\"] = encode_label(df[\"label\"])\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-grams:  0.2940640449523926\n",
      "Shape before conncat:  (3781, 100)\n",
      "Shape after conncat:  (3781, 200)\n",
      "Pos_tag: 3.6535422801971436\n",
      "Reading Score: 20.936655044555664\n",
      "Basic_Metrics: 0.02800154685974121\n",
      "Language: 18.05154538154602\n",
      "Char+Emoji: 0.14294958114624023\n",
      "(3781, 260)\n",
      "N-grams:  1.070641279220581\n",
      "Shape before conncat:  (14483, 100)\n",
      "Shape after conncat:  (14483, 200)\n",
      "Pos_tag: 10.957834243774414\n",
      "Reading Score: 74.65419578552246\n",
      "Basic_Metrics: 0.08410191535949707\n",
      "Language: 68.72832870483398\n",
      "Char+Emoji: 0.3479037284851074\n",
      "(14483, 260)\n"
     ]
    }
   ],
   "source": [
    "test_feature_df = feature_selection(test_df)\n",
    "print (test_feature_df.shape)\n",
    "\n",
    "train_feature_df = feature_selection(train_df)\n",
    "print (train_feature_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_df = normalize(train_feature_df)\n",
    "test_feature_df = normalize(test_feature_df)\n",
    "\n",
    "copy_train = train_feature_df\n",
    "copy_test = test_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=30)\n",
    "selector.fit(train_feature_df.drop(\"label\", axis=1), train_feature_df[\"label\"])\n",
    "\n",
    "cols = selector.get_support(indices=True)\n",
    "\n",
    "# Create new dataframes with desired columns\n",
    "X_train = train_feature_df.drop([\"label\"], axis=1).iloc[:, cols]\n",
    "X_test = test_feature_df.drop([\"label\"], axis=1).iloc[:, cols]\n",
    "\n",
    "Y_train = train_feature_df[\"label\"]\n",
    "Y_test = test_feature_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " [2, 3, 4, 5, 7, 10, 13, 14, 21, 22, 24, 33, 37, 38, 39, 42, 44, 46, 51, 52, 53, 55, 56, 57, 58, 63, 65, 67, 70, 71, 75, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 93, 94, 96, 99, 13, 44, 45, 52, 62, 76, 85, 'lang_en', 'lang_es', 'char_(', 'char_-', 'char_@']\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for c in X_train:\n",
    "    l.append(c)\n",
    "print(\"Features:\\n\", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: 0.8381380587146258\n",
      "Logistic: 0.8688177730759058\n"
     ]
    }
   ],
   "source": [
    "#Grid Search for hyperparameter classifiers\n",
    "\n",
    "def grid_search(X_train, Y_train, cls, param_grid):\n",
    "    grid_search = GridSearchCV(cls, param_grid, cv=5, scoring=\"accuracy\")\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def best_cls(X_train, X_test, Y_train, Y_test): \n",
    "    #Ridge\n",
    "    ridge = RidgeClassifier()\n",
    "    param_grid = [{\"alpha\" : range(1, 101)}]\n",
    "    ridge = grid_search(X_train, Y_train, ridge, param_grid)\n",
    "    \n",
    "    predictions_ridge = ridge.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions_ridge)\n",
    "    print(\"Ridge:\", accuracy)\n",
    "    \n",
    "    #Logistic\n",
    "    log = LogisticRegression()\n",
    "    param_grid = [{\"solver\" : [\"liblinear\", \"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}]\n",
    "    log = grid_search(X_train, Y_train, log, param_grid)\n",
    "    \n",
    "    predictions_log = log.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions_log)\n",
    "    print(\"Logistic:\", accuracy)\n",
    "    \n",
    "    #Support Vector\n",
    "    svc = SVC()\n",
    "    param_grid = [{\"C\" : np.linspace(0.1, 1, 9), \"gamma\" : [\"auto\"]}]\n",
    "    svc = grid_search(X_train, Y_train, svc, param_grid)\n",
    "    \n",
    "    predictions_svc = svc.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions_ridge)\n",
    "    print(\"SVC:\", accuracy)\n",
    "    \n",
    "    #Randomm Forrest\n",
    "    rfc = RandomForestClassifier()\n",
    "    param_grid = [{\"n_estimators\" : [1000], \"max_depth\" : range(1, 10, 1), \"min_samples_leaf\" : range(1, 10, 1)}]\n",
    "    rfc = grid_search(X_train, Y_train, rfc, param_grid)\n",
    "    \n",
    "    predictions_rfc = rfc.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions_rfc)\n",
    "    print(\"RFC:\", accuracy)\n",
    "    \n",
    "    return ridge, log, svc, rfc\n",
    "\n",
    "ridge, log, svc, rfc = best_cls(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge :\n",
      "F1: 0.7632901348849511 ; F1 fake: 0.828672705789681 ; F1 real: 0.6296296296296297 ; Roc Auc: 0.7315782524480929 \n",
      "\n",
      "Logistic :\n",
      "F1: 0.7553557259984132 ; F1 fake: 0.772349617813227 ; F1 real: 0.689119170984456 ; Roc Auc: 0.67176838264985 \n",
      "\n",
      "Support Vector Clasifier :\n",
      "F1: 0.678391959798995 ; F1 fake: 0.8091743119266055 ; F1 real: 0.5003123048094941 ; Roc Auc: 0.6730816808678921 \n",
      "\n",
      "Random Forrest Classifier :\n",
      "F1: 0.8799259455170589 ; F1 fake: 0.8504983388704319 ; F1 real: 0.9948119325551232 ; Roc Auc: 0.8143391142383576 \n",
      "\n",
      "Voting :\n",
      "F1: 0.8384025390108437 ; F1 fake: 0.8498745969186672 ; F1 real: 0.806060606060606 ; Roc Auc: 0.7904138844271931 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladc\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Best classifiers after runninng the grid search\n",
    "\n",
    "def print_score(pred, label, name):\n",
    "    cm = confusion_matrix(pred, label)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm = cm.diagonal()\n",
    "    \n",
    "    print(name, \":\")\n",
    "    print(\"F1:\", accuracy_score(label, pred), \n",
    "          \"; F1 fake:\", cm[0], \n",
    "          \"; F1 real:\", cm[1], \n",
    "          \"; Roc Auc:\", roc_auc_score(label, pred), \n",
    "          \"\\n\")\n",
    "\n",
    "def train_predict(cls, X_train, Y_train, X_test, Y_test, name):\n",
    "    cls.fit(X_train, Y_train)\n",
    "    predictions = cls.predict(X_test)\n",
    "    \n",
    "    print_score(predictions, Y_test, name)\n",
    "    \n",
    "    return cls\n",
    "\n",
    "\n",
    "ridge = RidgeClassifier(alpha=1, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
    "        tol=0.001)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "# fine-tuned: max_depth=2\n",
    "# grid-search: max_depth=9\n",
    "rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "rfc = RandomForestClassifier(max_depth=2, n_estimators=1000 )\n",
    "\n",
    "voting = VotingClassifier(estimators=[(\"log\", log), (\"svc\", svc), (\"rfc\", rfc)], voting=\"hard\")\n",
    "\n",
    "ridge = train_predict(ridge, X_train, Y_train, X_test, Y_test, \"Ridge\")\n",
    "log = train_predict(log, X_train, Y_train, X_test, Y_test, \"Logistic\")\n",
    "svc = train_predict(svc, X_train, Y_train, X_test, Y_test, \"Support Vector Clasifier\")\n",
    "rfc = train_predict(rfc, X_train, Y_train, X_test, Y_test, \"Random Forrest Classifier\")\n",
    "voting = train_predict(voting, X_train, Y_train, X_test, Y_test, \"Voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge :\n",
      "F1: 0.8709336154456493 ; F1 fake: 0.8642105263157894 ; F1 real: 0.8915145005370569 ; Roc Auc: 0.8213066772465475 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladc\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Ensemble learning\n",
    "\n",
    "voting = VotingClassifier(estimators=[(\"log\", log), (\"svc\", svc), (\"rfc\", rfc)], voting=\"hard\")\n",
    "# voting.fit(X_train, Y_train)\n",
    "# print_score(predictions, Y_test, \"Voting\")\n",
    "\n",
    "voting = train_predict(voting, X_train, Y_train, X_test, Y_test, \"Voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
